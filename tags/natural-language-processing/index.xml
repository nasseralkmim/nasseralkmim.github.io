<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>natural-language-processing on Nasser&#39;s personal website</title>
    <link>https://nasseralkmim.github.io/tags/natural-language-processing/</link>
    <description>Recent content in natural-language-processing on Nasser&#39;s personal website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© {year}</copyright>
    <lastBuildDate>Fri, 11 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://nasseralkmim.github.io/tags/natural-language-processing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Topic modeling</title>
      <link>https://nasseralkmim.github.io/notes/topic_modelig/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nasseralkmim.github.io/notes/topic_modelig/</guid>
      <description>Introduction  Topic modeling is a form of semantic analysis, a step forwarding finding meaning from word counts. This analysis allows discovery of document topic without trainig data. It involves counting words and grouping similar word patterns to describe the data.
  Latent Dirichlet Allocation   Latent Dirichlet Allocation (LDA) is one topic modeling technique. It can infer the probability distribution of words for each topic, characterizing it.</description>
    </item>
    
    <item>
      <title>NLP with Python</title>
      <link>https://nasseralkmim.github.io/notes/nlp-with-python/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nasseralkmim.github.io/notes/nlp-with-python/</guid>
      <description>Introduction  This is an attempt to compile different sources of informations about Natural Language processing with python.
  Techiniques used in NLP  Tokenization  Converts text into segments (n-grams) that could represent a word, two words or more. During this step, usually it is performed some kind of vocabulary reduction such as normalization, stemming, lemmatization and removing stop words.
Tools    NLTK: string processing library, built by academics.</description>
    </item>
    
    <item>
      <title>Text processing with spaCy</title>
      <link>https://nasseralkmim.github.io/notes/text-processing-with-spacy/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nasseralkmim.github.io/notes/text-processing-with-spacy/</guid>
      <description>Introduction   spaCy is a library for Natural Language Processing (NLP) in python. It offers multiple solutions for text processing such as tokenization, named entity recognition, word vectors, part of speech tagging. The alternative is the library NLTK which seems to be used mostly in academia whereas spaCy is recommended for production use.
  Load the language model  We need to download the models for the language with python -m spacy download model-name.</description>
    </item>
    
    <item>
      <title>Sentiment analysis on IMDB dataset</title>
      <link>https://nasseralkmim.github.io/notes/sentiment-analysis/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nasseralkmim.github.io/notes/sentiment-analysis/</guid>
      <description>Introduction   This is as exemple from the excellent book by François Chollet on deep learning. My idea here is to further detail the explanation with the code output, which the book does not contain. And since tensorflow 2.0 was released, I will be using tf.keras instead.
 The goal of this example is
 The steps are
  Load data   Load imdb data from keras datasets.</description>
    </item>
    
  </channel>
</rss>
