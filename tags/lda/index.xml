<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LDA on Nasser&#39;s personal website</title>
    <link>https://nasseralkmim.github.io/tags/lda/</link>
    <description>Recent content in LDA on Nasser&#39;s personal website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© {year}</copyright>
    <lastBuildDate>Fri, 11 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://nasseralkmim.github.io/tags/lda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Topic modeling</title>
      <link>https://nasseralkmim.github.io/notes/topic_modelig/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nasseralkmim.github.io/notes/topic_modelig/</guid>
      <description>Introduction  Topic modeling is a form of semantic analysis, a step forwarding finding meaning from word counts. This analysis allows discovery of document topic without trainig data. It involves counting words and grouping similar word patterns to describe the data.
  Latent Dirichlet Allocation   Latent Dirichlet Allocation (LDA) is one topic modeling technique. It can infer the probability distribution of words for each topic, characterizing it.</description>
    </item>
    
  </channel>
</rss>
